{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from core import log\n",
    "\n",
    "from harp.providers.NASA import MERRA2\n",
    "\n",
    "# MERRA2.hourly.raster.M2I1NXASM.get(day=date(2012, 12, 12))\n",
    "# MERRA2.daily.raster.M2IUNXGAS.get(day=date(2012, 12, 12))\n",
    "\n",
    "# log.info(MERRA2.hourly.raster.M2I1NXASM.variables)\n",
    "# log.info(MERRA2.hourly.raster.M2I1NXASM.infos)\n",
    "# log.info(MERRA2.hourly.raster.M2I3NXGAS.infos)\n",
    "\n",
    "log.info(MERRA2.daily.raster.M2IUNXGAS.auth)\n",
    "\n",
    "# MERRA2.hourly.raster.M2I1NXASM.download(\n",
    "#     variables=[\"U2M\", \"TROPT\",\"TROPPB\",\"T2M\",\"TQI\", \"SLP\", \"V2M\"], \n",
    "#     day=date(2012, 12, 12),\n",
    "#     offline=True,\n",
    "# )\n",
    "\n",
    "p1 = MERRA2.hourly.raster.M2I1NXASM()\n",
    "\n",
    "p2 = MERRA2.hourly.raster.M2I1NXASM(\n",
    "    dir_storage=\"/mnt/ceph/user/joackim/data/test/\",\n",
    "    harmonize = False\n",
    ")\n",
    "\n",
    "log.info(p1.config)\n",
    "log.info(p2.config)\n",
    "# log.info(MERRA2.hourly.raster.M2I1NXASM.config)\n",
    "\n",
    "p1.get(\n",
    "    variables=[\"surface_pressure\", \"ozone\", \"temperature\", \"sea_level_pressure\"],\n",
    "    time=date(2012, 12, 12),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# log.info(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from core import log\n",
    "\n",
    "from harp.providers.NASA import MERRA2\n",
    "\n",
    "p1 = MERRA2.hourly.raster.M2I1NXASM()\n",
    "\n",
    "p2 = MERRA2.hourly.raster.M2I1NXLFO(\n",
    "    dir_storage=\"/mnt/ceph/user/joackim/data/test/\",\n",
    "    harmonize = False\n",
    ")\n",
    "\n",
    "log.info(p1)\n",
    "log.info(p2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m[DEBUG] \u001b[93m\u001b[92m18:23:01 \u001b[0mQuerying M2I1NXASM for variables PS, TO3 on 2012-12-12 [datetime.datetime(2012, 12, 12, 18, 0), datetime.datetime(2012, 12, 12, 17, 0)]\u001b[0m\n",
      "\u001b[94m[INFO] \u001b[93m\u001b[92m18:23:49 \u001b[0mWriting:/tmp/tmp_m4qoyj0/NASA/MERRA2/M2I1NXASM/2012/12/12/MERRA2_M2I1NXASM_global_2012-12-12T18:00Z__PS.nc\u001b[0m\n",
      "\u001b[95m[DEBUG] \u001b[93m\u001b[92m18:23:50 \u001b[0mMoving \"/tmp/tmp8dgtv4_m/MERRA2_M2I1NXASM_global_2012-12-12T18:00Z__PS.nc\" to \"/tmp/tmp_m4qoyj0/NASA/MERRA2/M2I1NXASM/2012/12/12/MERRA2_M2I1NXASM_global_2012-12-12T18:00Z__PS.nc\"...\u001b[0m\n",
      "\u001b[94m[INFO] \u001b[93m\u001b[92m18:23:53 \u001b[0mWriting:/tmp/tmp_m4qoyj0/NASA/MERRA2/M2I1NXASM/2012/12/12/MERRA2_M2I1NXASM_global_2012-12-12T17:00Z__PS.nc\u001b[0m\n",
      "\u001b[95m[DEBUG] \u001b[93m\u001b[92m18:23:53 \u001b[0mMoving \"/tmp/tmprte1ernv/MERRA2_M2I1NXASM_global_2012-12-12T17:00Z__PS.nc\" to \"/tmp/tmp_m4qoyj0/NASA/MERRA2/M2I1NXASM/2012/12/12/MERRA2_M2I1NXASM_global_2012-12-12T17:00Z__PS.nc\"...\u001b[0m\n",
      "\u001b[94m[INFO] \u001b[93m\u001b[92m18:23:57 \u001b[0mWriting:/tmp/tmp_m4qoyj0/NASA/MERRA2/M2I1NXASM/2012/12/12/MERRA2_M2I1NXASM_global_2012-12-12T18:00Z__TO3.nc\u001b[0m\n",
      "\u001b[95m[DEBUG] \u001b[93m\u001b[92m18:23:57 \u001b[0mMoving \"/tmp/tmpg9sw7uo1/MERRA2_M2I1NXASM_global_2012-12-12T18:00Z__TO3.nc\" to \"/tmp/tmp_m4qoyj0/NASA/MERRA2/M2I1NXASM/2012/12/12/MERRA2_M2I1NXASM_global_2012-12-12T18:00Z__TO3.nc\"...\u001b[0m\n",
      "\u001b[94m[INFO] \u001b[93m\u001b[92m18:24:01 \u001b[0mWriting:/tmp/tmp_m4qoyj0/NASA/MERRA2/M2I1NXASM/2012/12/12/MERRA2_M2I1NXASM_global_2012-12-12T17:00Z__TO3.nc\u001b[0m\n",
      "\u001b[95m[DEBUG] \u001b[93m\u001b[92m18:24:01 \u001b[0mMoving \"/tmp/tmpr7mpdp5a/MERRA2_M2I1NXASM_global_2012-12-12T17:00Z__TO3.nc\" to \"/tmp/tmp_m4qoyj0/NASA/MERRA2/M2I1NXASM/2012/12/12/MERRA2_M2I1NXASM_global_2012-12-12T17:00Z__TO3.nc\"...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not find any dimension coordinates to use to order the datasets for concatenation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     10\u001b[0m variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurface_pressure\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mozone\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;66;03m#, \"temperature\", \"sea_level_pressure\"]\u001b[39;00m\n\u001b[1;32m     12\u001b[0m merra2 \u001b[38;5;241m=\u001b[39m MERRA2\u001b[38;5;241m.\u001b[39mhourly\u001b[38;5;241m.\u001b[39mM2I1NXASM(\n\u001b[1;32m     13\u001b[0m     dir_storage \u001b[38;5;241m=\u001b[39m Path(tmpdir)\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mmerra2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdatetime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2012\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m17\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m variables:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m ds\u001b[38;5;241m.\u001b[39mdata_vars\n",
      "File \u001b[0;32m~/projects/core/core/static/interface.py:103\u001b[0m, in \u001b[0;36minterface.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     mess \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Parameter \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m still unchecked after interface call, module error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m expected_signature]\n\u001b[1;32m    101\u001b[0m     log\u001b[38;5;241m.\u001b[39merror(mess, e\u001b[38;5;241m=\u001b[39mInterfaceException)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/harp/harp/backend/baseprovider.py:50\u001b[0m, in \u001b[0;36mBaseDatasetProvider.get\u001b[0;34m(self, variables, time, area, raw_query)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# std_vars = variables\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# TODO: download\u001b[39;00m\n\u001b[1;32m     49\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload(variables\u001b[38;5;241m=\u001b[39mraw_vars, time\u001b[38;5;241m=\u001b[39mtime, offline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffline\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 50\u001b[0m ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_mfdataset(files, concat_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, combine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnested\u001b[39m\u001b[38;5;124m'\u001b[39m,)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# harmonize if not disabled\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mharmonize\u001b[39m\u001b[38;5;124m\"\u001b[39m): \n",
      "File \u001b[0;32m~/.conda/envs/harp/lib/python3.13/site-packages/xarray/backends/api.py:1607\u001b[0m, in \u001b[0;36mopen_mfdataset\u001b[0;34m(paths, chunks, concat_dim, compat, preprocess, engine, data_vars, coords, combine, parallel, join, attrs_file, combine_attrs, **kwargs)\u001b[0m\n\u001b[1;32m   1594\u001b[0m     combined \u001b[38;5;241m=\u001b[39m _nested_combine(\n\u001b[1;32m   1595\u001b[0m         datasets,\n\u001b[1;32m   1596\u001b[0m         concat_dims\u001b[38;5;241m=\u001b[39mconcat_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1602\u001b[0m         combine_attrs\u001b[38;5;241m=\u001b[39mcombine_attrs,\n\u001b[1;32m   1603\u001b[0m     )\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m combine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby_coords\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1605\u001b[0m     \u001b[38;5;66;03m# Redo ordering from coordinates, ignoring how they were ordered\u001b[39;00m\n\u001b[1;32m   1606\u001b[0m     \u001b[38;5;66;03m# previously\u001b[39;00m\n\u001b[0;32m-> 1607\u001b[0m     combined \u001b[38;5;241m=\u001b[39m \u001b[43mcombine_by_coords\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1617\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is an invalid option for the keyword argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1618\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ``combine``\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1619\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/harp/lib/python3.13/site-packages/xarray/core/combine.py:973\u001b[0m, in \u001b[0;36mcombine_by_coords\u001b[0;34m(data_objects, compat, data_vars, coords, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    969\u001b[0m     grouped_by_vars \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mgroupby(sorted_datasets, key\u001b[38;5;241m=\u001b[39mvars_as_keys)\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;66;03m# Perform the multidimensional combine on each group of data variables\u001b[39;00m\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;66;03m# before merging back together\u001b[39;00m\n\u001b[0;32m--> 973\u001b[0m     concatenated_grouped_by_data_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_combine_single_variable_hypercube\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatasets_with_same_vars\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets_with_same_vars\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgrouped_by_vars\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[1;32m    987\u001b[0m     concatenated_grouped_by_data_vars,\n\u001b[1;32m    988\u001b[0m     compat\u001b[38;5;241m=\u001b[39mcompat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    991\u001b[0m     combine_attrs\u001b[38;5;241m=\u001b[39mcombine_attrs,\n\u001b[1;32m    992\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/harp/lib/python3.13/site-packages/xarray/core/combine.py:974\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    969\u001b[0m     grouped_by_vars \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mgroupby(sorted_datasets, key\u001b[38;5;241m=\u001b[39mvars_as_keys)\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;66;03m# Perform the multidimensional combine on each group of data variables\u001b[39;00m\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;66;03m# before merging back together\u001b[39;00m\n\u001b[1;32m    973\u001b[0m     concatenated_grouped_by_data_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m--> 974\u001b[0m         \u001b[43m_combine_single_variable_hypercube\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatasets_with_same_vars\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mvars\u001b[39m, datasets_with_same_vars \u001b[38;5;129;01min\u001b[39;00m grouped_by_vars\n\u001b[1;32m    984\u001b[0m     )\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[1;32m    987\u001b[0m     concatenated_grouped_by_data_vars,\n\u001b[1;32m    988\u001b[0m     compat\u001b[38;5;241m=\u001b[39mcompat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    991\u001b[0m     combine_attrs\u001b[38;5;241m=\u001b[39mcombine_attrs,\n\u001b[1;32m    992\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/harp/lib/python3.13/site-packages/xarray/core/combine.py:634\u001b[0m, in \u001b[0;36m_combine_single_variable_hypercube\u001b[0;34m(datasets, fill_value, data_vars, coords, compat, join, combine_attrs)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(datasets) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one Dataset is required to resolve variable names \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor combined hypercube.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    632\u001b[0m     )\n\u001b[0;32m--> 634\u001b[0m combined_ids, concat_dims \u001b[38;5;241m=\u001b[39m \u001b[43m_infer_concat_order_from_coords\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;66;03m# check that datasets form complete hypercube\u001b[39;00m\n\u001b[1;32m    638\u001b[0m     _check_shape_tile_ids(combined_ids)\n",
      "File \u001b[0;32m~/.conda/envs/harp/lib/python3.13/site-packages/xarray/core/combine.py:159\u001b[0m, in \u001b[0;36m_infer_concat_order_from_coords\u001b[0;34m(datasets)\u001b[0m\n\u001b[1;32m    153\u001b[0m             tile_ids \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    154\u001b[0m                 tile_id \u001b[38;5;241m+\u001b[39m (position,)\n\u001b[1;32m    155\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m tile_id, position \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tile_ids, order, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    156\u001b[0m             ]\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(datasets) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m concat_dims:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find any dimension coordinates to use to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder the datasets for concatenation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    164\u001b[0m combined_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(tile_ids, datasets, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m combined_ids, concat_dims\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find any dimension coordinates to use to order the datasets for concatenation"
     ]
    }
   ],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from core import log\n",
    "from harp.providers.NASA import MERRA2\n",
    "\n",
    "with TemporaryDirectory() as tmpdir:\n",
    "    \n",
    "    variables=[\"surface_pressure\", \"ozone\"] #, \"temperature\", \"sea_level_pressure\"]\n",
    "    \n",
    "    merra2 = MERRA2.hourly.M2I1NXASM(\n",
    "        dir_storage = Path(tmpdir)\n",
    "    )\n",
    "    \n",
    "    ds = merra2.get(\n",
    "        variables = variables,\n",
    "        time = datetime(2012, 12, 12, 17, 15),\n",
    "        raw_query=False\n",
    "    )\n",
    "\n",
    "    for var in variables:\n",
    "        assert var in ds.data_vars\n",
    "    \n",
    "    log.info(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from harp.backend.nomenclature import Nomenclature\n",
    "from core import log\n",
    "from pathlib import Path\n",
    "\n",
    "import harp.config\n",
    "\n",
    "raw = Path(\"/home/Joackim/projects/harp/tests/raw_merra2_nomenclature.csv\")\n",
    "std = Path(\"/home/Joackim/projects/harp/harp/std_nomenclature.csv\")\n",
    "\n",
    "n = Nomenclature(raw, cols=[\"harp_name\", \"raw_name\"], raw_col=\"raw_name\", context=\"test\")\n",
    "\n",
    "# log.info(n.raw.columns)\n",
    "# log.info(n.raw)\n",
    "\n",
    "# log.debug(\"-\" * 30)\n",
    "# log.info(n.dst)\n",
    "\n",
    "# nstd = n.raw_to_std(\"TOTEXTTAU\")\n",
    "# nraw = n.std_to_raw(\"angstr_coef_550\")\n",
    "nstd = n.get_std_name(\"TOTEXTTAU\")\n",
    "log.info(nstd)\n",
    "\n",
    "nstd = n.get_std_name(\"CLDMID\")\n",
    "log.info(nstd)\n",
    "\n",
    "# nraw = n.get_raw_name(\"aod_550\")\n",
    "# log.info(nraw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import inspect\n",
    "from core import log\n",
    "from pathlib import Path\n",
    "\n",
    "from harp.providers.NASA import MERRA2\n",
    "\n",
    "merra2  = MERRA2.hourly.M2I1NXASM(\n",
    "    dir_storage=Path(\"/mnt/ceph/data\")\n",
    ")\n",
    "# provider2 = MERRA2.daily.M2IUNXASM(dict(\n",
    "#     dir_storage=Path(\"/mnt/ceph/data\")\n",
    "#     )\n",
    "# )\n",
    "\n",
    "log.info(merra2)\n",
    "# log.info(provider2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pprint\n",
    "import numpy as np\n",
    "\n",
    "from core import log\n",
    "from harp.backend.timespecs import RegularTimesteps\n",
    "\n",
    "t = RegularTimesteps(start=timedelta(minutes=30), count=24)\n",
    "ids = t.get_encompassing_timesteps(datetime(2012, 11, 27, 0, 11, 23))\n",
    "\n",
    "log.info(ids)\n",
    "\n",
    "pprint.pprint(t.aggregate_per_day(ids, complete_days=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "from pathlib import Path\n",
    "\n",
    "from harp.providers.ECMWF.C3S import ERA5\n",
    "from datetime import datetime\n",
    "import cdsapi\n",
    "\n",
    "# era5 = ERA5.hourly.GlobalReanalysis(\n",
    "#     dir_storage = \"/mnt/ceph/user/joackim/data/test\"\n",
    "# )\n",
    "\n",
    "# ds = era5.get(\n",
    "#     variables = [\"snow_albedo\", \"mean_sea_level_pressure\"],\n",
    "#     time = datetime(2018, 12, 15, 22, 14, 0),\n",
    "#     raw_query=True\n",
    "# )\n",
    "\n",
    "\n",
    "with TemporaryDirectory() as tmpdir:\n",
    "    tmpdir = Path(tmpdir)\n",
    "\n",
    "    era5 = ERA5.hourly.GlobalReanalysis(\n",
    "        dir_storage = tmpdir\n",
    "    )\n",
    "    print()\n",
    "    # cd /mnt/ceph/user/joackim/data/test/ECMWF/C3S/reanalysis-era5-single-levels/2018/12/15\n",
    "    ds = era5.get(\n",
    "        variables = [\"lake_ice_temperature\"],\n",
    "        time = datetime(2018, 12, 15, 23, 0, 0),\n",
    "        raw_query=True\n",
    "    )\n",
    "\n",
    "print()\n",
    "# log.info(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from harp.providers.ECMWF.C3S import ERA5\n",
    "from datetime import datetime\n",
    "\n",
    "era5 = ERA5.hourly.GlobalReanalysisVolumetric(\n",
    "    dir_storage = \"/mnt/ceph/user/joackim/data/test\"\n",
    ")\n",
    "\n",
    "ds = era5.get(\n",
    "    variables = [\"relative_humidity\"],\n",
    "    time = datetime(2018, 12, 15, 23, 0, 0),\n",
    "    raw_query=True\n",
    ")\n",
    "\n",
    "print()\n",
    "\n",
    "ds = era5.get(\n",
    "    variables = [\"relative_humidity\", \"temperature\"],\n",
    "    time = datetime(2018, 12, 15, 23, 0, 0),\n",
    "    raw_query=True\n",
    ")\n",
    "\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "harp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
